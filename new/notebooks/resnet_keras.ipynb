{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  data_format=\"channels_first\",\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 1, 100, 100)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 16, 100, 100) 160         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 100, 100) 400         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 100, 100) 0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 16, 100, 100) 2320        activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 100, 100) 400         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 100, 100) 0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 16, 100, 100) 2320        activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 100, 100) 400         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 16, 100, 100) 0           batch_normalization_201[0][0]    \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 100, 100) 0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 16, 100, 100) 2320        activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 100, 100) 400         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 100, 100) 0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 16, 100, 100) 2320        activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 100, 100) 400         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 16, 100, 100) 0           batch_normalization_203[0][0]    \n",
      "                                                                 activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 100, 100) 0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 16, 100, 100) 2320        activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 100, 100) 400         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 100, 100) 0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 16, 100, 100) 2320        activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 100, 100) 400         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 16, 100, 100) 0           batch_normalization_205[0][0]    \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 100, 100) 0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 32, 50, 50)   4640        activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 32, 50, 50)   200         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 32, 50, 50)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 32, 50, 50)   9248        activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 32, 50, 50)   200         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 32, 50, 50)   544         activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 32, 50, 50)   0           batch_normalization_207[0][0]    \n",
      "                                                                 conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 32, 50, 50)   0           add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 32, 50, 50)   9248        activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 32, 50, 50)   200         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 32, 50, 50)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 32, 50, 50)   9248        activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 32, 50, 50)   200         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 32, 50, 50)   0           batch_normalization_209[0][0]    \n",
      "                                                                 activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 32, 50, 50)   0           add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 32, 50, 50)   9248        activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 32, 50, 50)   200         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 32, 50, 50)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 32, 50, 50)   9248        activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 32, 50, 50)   200         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 32, 50, 50)   0           batch_normalization_211[0][0]    \n",
      "                                                                 activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 32, 50, 50)   0           add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 64, 25, 25)   18496       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 64, 25, 25)   100         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 64, 25, 25)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 64, 25, 25)   36928       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 64, 25, 25)   100         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 64, 25, 25)   2112        activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 64, 25, 25)   0           batch_normalization_213[0][0]    \n",
      "                                                                 conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 64, 25, 25)   0           add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 64, 25, 25)   36928       activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 64, 25, 25)   100         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 64, 25, 25)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 64, 25, 25)   36928       activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 64, 25, 25)   100         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 64, 25, 25)   0           batch_normalization_215[0][0]    \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 64, 25, 25)   0           add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 64, 25, 25)   36928       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 64, 25, 25)   100         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 64, 25, 25)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 64, 25, 25)   36928       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 64, 25, 25)   100         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 64, 25, 25)   0           batch_normalization_217[0][0]    \n",
      "                                                                 activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 64, 25, 25)   0           add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 64, 3, 3)     0           activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 576)          0           average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 10)           5770        flatten_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 281,122\n",
      "Trainable params: 278,822\n",
      "Non-trainable params: 2,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# manual implementation of resnet20v1\n",
    "\n",
    "input_shape = (1, 100, 100)\n",
    "inputs = Input(shape=input_shape)                                     #output (1, 100, 100)\n",
    "y = resnet_layer(inputs=inputs, num_filters=16, strides=1)            #output (16, 100, 100)\n",
    "\n",
    "#stack 0\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "#stack 1\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=2)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "#linear projection\n",
    "y = resnet_layer(inputs=y, num_filters=32, kernel_size=1, strides=2, activation=None, batch_normalization=False)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "#stack 2\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=2)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "#linear projection\n",
    "y = resnet_layer(inputs=y, num_filters=64, kernel_size=1, strides=2, activation=None, batch_normalization=False)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=8, data_format='channels_first')(y)\n",
    "y = Flatten()(x)\n",
    "outputs = Dense(1, activation='sigmoid', kernel_initializer='he_normal')(y)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 1, 100, 100)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 16, 100, 100) 160         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 16, 100, 100) 400         conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 16, 100, 100) 0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 16, 100, 100) 272         activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 16, 100, 100) 400         conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 16, 100, 100) 0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 16, 100, 100) 2320        activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 16, 100, 100) 400         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 16, 100, 100) 0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 64, 100, 100) 1088        activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 64, 100, 100) 1088        activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 64, 100, 100) 0           conv2d_272[0][0]                 \n",
      "                                                                 conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 64, 100, 100) 400         add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 64, 100, 100) 0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 16, 100, 100) 1040        activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 16, 100, 100) 400         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 16, 100, 100) 0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 16, 100, 100) 2320        activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 16, 100, 100) 400         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 16, 100, 100) 0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 64, 100, 100) 1088        activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 64, 100, 100) 0           add_109[0][0]                    \n",
      "                                                                 conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 64, 100, 100) 400         add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 64, 100, 100) 0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 64, 50, 50)   4160        activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 64, 50, 50)   200         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 64, 50, 50)   0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 64, 50, 50)   36928       activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 64, 50, 50)   200         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 64, 50, 50)   0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 128, 50, 50)  8320        add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 128, 50, 50)  8320        activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 128, 50, 50)  0           conv2d_279[0][0]                 \n",
      "                                                                 conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 128, 50, 50)  200         add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 128, 50, 50)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 64, 50, 50)   8256        activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 64, 50, 50)   200         conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 64, 50, 50)   0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 64, 50, 50)   36928       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 64, 50, 50)   200         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 64, 50, 50)   0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 128, 50, 50)  8320        activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 128, 50, 50)  0           add_111[0][0]                    \n",
      "                                                                 conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 128, 50, 50)  200         add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 128, 50, 50)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 128, 25, 25)  16512       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 128, 25, 25)  100         conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 128, 25, 25)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 128, 25, 25)  147584      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 128, 25, 25)  100         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 128, 25, 25)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 256, 25, 25)  33024       add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 256, 25, 25)  33024       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 256, 25, 25)  0           conv2d_286[0][0]                 \n",
      "                                                                 conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 256, 25, 25)  100         add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 256, 25, 25)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 128, 25, 25)  32896       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 128, 25, 25)  100         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 128, 25, 25)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 128, 25, 25)  147584      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 128, 25, 25)  100         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 128, 25, 25)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 256, 25, 25)  33024       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 256, 25, 25)  0           add_113[0][0]                    \n",
      "                                                                 conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 256, 25, 25)  100         add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 256, 25, 25)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 256, 3, 3)    0           activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 2304)         0           average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            2305        flatten_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 571,161\n",
      "Trainable params: 568,861\n",
      "Non-trainable params: 2,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#resnet20v2\n",
    "\n",
    "input_shape = (1, 100, 100)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = resnet_layer(inputs=inputs, num_filters=16, conv_first=True)\n",
    "\n",
    "# stage 0\n",
    "# bottleneck residual unit\n",
    "y = resnet_layer(inputs=x, num_filters=16, kernel_size=1, strides=1, activation=None, batch_normalization=False, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=16, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=64, kernel_size=1, conv_first=False)\n",
    "\n",
    "# linear projection residual shortcut connection to match\n",
    "# changed dims\n",
    "x = resnet_layer(inputs=x, num_filters=64, kernel_size=1, strides=1, activation=None, batch_normalization=False)\n",
    "x = keras.layers.add([x, y])\n",
    "\n",
    "# bottleneck residual unit\n",
    "y = resnet_layer(inputs=x, num_filters=16, kernel_size=1, strides=1, activation='relu', batch_normalization=True, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=16, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=64, kernel_size=1, conv_first=False)\n",
    "\n",
    "x = keras.layers.add([x, y])\n",
    "\n",
    "# stage 1\n",
    "\n",
    "# bottleneck residual unit\n",
    "y = resnet_layer(inputs=x, num_filters=64, kernel_size=1, strides=2, activation='relu', batch_normalization=True, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=64, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=128, kernel_size=1, conv_first=False)\n",
    "\n",
    "# linear projection residual shortcut connection to match\n",
    "# changed dims\n",
    "x = resnet_layer(inputs=x, num_filters=128, kernel_size=1, strides=2, activation=None, batch_normalization=False)\n",
    "x = keras.layers.add([x, y])\n",
    "\n",
    "# bottleneck residual unit\n",
    "y = resnet_layer(inputs=x, num_filters=64, kernel_size=1, strides=1, activation='relu', batch_normalization=True, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=64, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=128, kernel_size=1, conv_first=False)\n",
    "\n",
    "x = keras.layers.add([x, y])\n",
    "\n",
    "# stage 2\n",
    "\n",
    "# bottleneck residual unit\n",
    "y = resnet_layer(inputs=x, num_filters=128, kernel_size=1, strides=2, activation='relu', batch_normalization=True, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=128, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=256, kernel_size=1, conv_first=False)\n",
    "\n",
    "# linear projection residual shortcut connection to match\n",
    "# changed dims\n",
    "x = resnet_layer(inputs=x,num_filters=256, kernel_size=1, strides=2, activation=None, batch_normalization=False)\n",
    "x = keras.layers.add([x, y])\n",
    "\n",
    "# bottleneck residual unit\n",
    "y = resnet_layer(inputs=x, num_filters=128, kernel_size=1, strides=1, activation='relu', batch_normalization=True, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=128, conv_first=False)\n",
    "y = resnet_layer(inputs=y, num_filters=256, kernel_size=1, conv_first=False)\n",
    "\n",
    "x = keras.layers.add([x, y])\n",
    "\n",
    "\n",
    "# Add classifier on top.\n",
    "# v2 has BN-ReLU before Pooling\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = AveragePooling2D(pool_size=8, data_format='channels_first')(x)\n",
    "y = Flatten()(x)\n",
    "outputs = Dense(1, activation='sigmoid', kernel_initializer='he_normal')(y)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 1, 100, 100)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 16, 100, 100) 160         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 16, 100, 100) 400         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 16, 100, 100) 0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 16, 100, 100) 272         activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 16, 100, 100) 400         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 16, 100, 100) 0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 16, 100, 100) 2320        activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 16, 100, 100) 400         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 16, 100, 100) 0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 64, 100, 100) 1088        activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 64, 100, 100) 1088        activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_121 (Add)                   (None, 64, 100, 100) 0           conv2d_316[0][0]                 \n",
      "                                                                 conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 64, 100, 100) 400         add_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 64, 100, 100) 0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 16, 100, 100) 1040        activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 16, 100, 100) 400         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 16, 100, 100) 0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 16, 100, 100) 2320        activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 16, 100, 100) 400         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 16, 100, 100) 0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 64, 100, 100) 1088        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_122 (Add)                   (None, 64, 100, 100) 0           add_121[0][0]                    \n",
      "                                                                 conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 64, 100, 100) 400         add_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 64, 100, 100) 0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 64, 50, 50)   4160        activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 64, 50, 50)   200         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 64, 50, 50)   0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 64, 50, 50)   36928       activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 64, 50, 50)   200         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 64, 50, 50)   0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 128, 50, 50)  8320        add_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 128, 50, 50)  8320        activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_123 (Add)                   (None, 128, 50, 50)  0           conv2d_323[0][0]                 \n",
      "                                                                 conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 128, 50, 50)  200         add_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 128, 50, 50)  0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 64, 50, 50)   8256        activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 64, 50, 50)   200         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 64, 50, 50)   0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 64, 50, 50)   36928       activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 64, 50, 50)   200         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 64, 50, 50)   0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 128, 50, 50)  8320        activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_124 (Add)                   (None, 128, 50, 50)  0           add_123[0][0]                    \n",
      "                                                                 conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 128, 50, 50)  200         add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 128, 50, 50)  0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 128, 25, 25)  16512       activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 128, 25, 25)  100         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 128, 25, 25)  0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 128, 25, 25)  147584      activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 128, 25, 25)  100         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 128, 25, 25)  0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 256, 25, 25)  33024       add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 256, 25, 25)  33024       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_125 (Add)                   (None, 256, 25, 25)  0           conv2d_330[0][0]                 \n",
      "                                                                 conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 256, 25, 25)  100         add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 256, 25, 25)  0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 128, 25, 25)  32896       activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 128, 25, 25)  100         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 128, 25, 25)  0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 128, 25, 25)  147584      activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 128, 25, 25)  100         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 128, 25, 25)  0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 256, 25, 25)  33024       activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_126 (Add)                   (None, 256, 25, 25)  0           add_125[0][0]                    \n",
      "                                                                 conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 256, 25, 25)  100         add_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 256, 25, 25)  0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 256, 3, 3)    0           activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 2304)         0           average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            2305        flatten_19[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 571,161\n",
      "Trainable params: 568,861\n",
      "Non-trainable params: 2,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 100, 100)\n",
    "depth = 20\n",
    "num_filters_in = 16\n",
    "num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "# v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "x = resnet_layer(inputs=inputs,\n",
    "                 num_filters=num_filters_in,\n",
    "                 conv_first=True)\n",
    "\n",
    "# Instantiate the stack of residual units\n",
    "for stage in range(3):\n",
    "    for res_block in range(num_res_blocks):\n",
    "        activation = 'relu'\n",
    "        batch_normalization = True\n",
    "        strides = 1\n",
    "        if stage == 0:\n",
    "            num_filters_out = num_filters_in * 4\n",
    "            if res_block == 0:  # first layer and first stage\n",
    "                activation = None\n",
    "                batch_normalization = False\n",
    "        else:\n",
    "            num_filters_out = num_filters_in * 2\n",
    "            if res_block == 0:  # first layer but not first stage\n",
    "                strides = 2    # downsample\n",
    "\n",
    "        # bottleneck residual unit\n",
    "        y = resnet_layer(inputs=x,\n",
    "                         num_filters=num_filters_in,\n",
    "                         kernel_size=1,\n",
    "                         strides=strides,\n",
    "                         activation=activation,\n",
    "                         batch_normalization=batch_normalization,\n",
    "                         conv_first=False)\n",
    "        y = resnet_layer(inputs=y,\n",
    "                         num_filters=num_filters_in,\n",
    "                         conv_first=False)\n",
    "        y = resnet_layer(inputs=y,\n",
    "                         num_filters=num_filters_out,\n",
    "                         kernel_size=1,\n",
    "                         conv_first=False)\n",
    "        if res_block == 0:\n",
    "            # linear projection residual shortcut connection to match\n",
    "            # changed dims\n",
    "            x = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=None,\n",
    "                             batch_normalization=False)\n",
    "        x = keras.layers.add([x, y])\n",
    "\n",
    "    num_filters_in = num_filters_out\n",
    "\n",
    "# Add classifier on top.\n",
    "# v2 has BN-ReLU before Pooling\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = AveragePooling2D(pool_size=8, data_format='channels_first')(x)\n",
    "y = Flatten()(x)\n",
    "outputs = Dense(1,\n",
    "                activation='softmax',\n",
    "                kernel_initializer='he_normal')(y)\n",
    "\n",
    "# Instantiate model.\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def squeeze_excite_block(input, ratio=16):\n",
    "    ''' Create a channel-wise squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "    Returns: a keras tensor\n",
    "    References\n",
    "    -   [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = init._keras_shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 100, 100, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 100, 100, 16) 304         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 100, 100, 16) 64          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 100, 100, 16) 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 100, 100, 16) 2320        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 100, 100, 16) 64          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 100, 100, 16) 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 100, 100, 16) 2320        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 100, 100, 16) 64          conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 16)           0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 16)     0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 1, 1)      16          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 1, 16)     16          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 100, 100, 16) 0           batch_normalization_59[0][0]     \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 100, 100, 16) 0           multiply_1[0][0]                 \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 100, 100, 16) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 100, 100, 16) 2320        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 100, 100, 16) 64          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 100, 100, 16) 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 100, 100, 16) 2320        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 100, 100, 16) 64          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 16)           0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 16)     0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 1, 1)      16          reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1, 16)     16          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 100, 100, 16) 0           batch_normalization_61[0][0]     \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 100, 100, 16) 0           multiply_2[0][0]                 \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 100, 100, 16) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 100, 100, 16) 2320        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 100, 100, 16) 64          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 100, 100, 16) 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 100, 100, 16) 2320        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 100, 100, 16) 64          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 16)           0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 16)     0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 1, 1)      16          reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 1, 16)     16          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 100, 100, 16) 0           batch_normalization_63[0][0]     \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 100, 100, 16) 0           multiply_3[0][0]                 \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 100, 100, 16) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 50, 50, 32)   4640        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 50, 50, 32)   128         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 50, 50, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 50, 50, 32)   9248        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 50, 50, 32)   128         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 32)           0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1, 32)     0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 1, 2)      64          reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 1, 32)     64          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 50, 50, 32)   0           batch_normalization_65[0][0]     \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 50, 50, 32)   544         activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 50, 50, 32)   0           multiply_4[0][0]                 \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 50, 50, 32)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 50, 50, 32)   9248        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 50, 50, 32)   128         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 50, 50, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 50, 50, 32)   9248        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 50, 50, 32)   128         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 32)           0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1, 32)     0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 1, 2)      64          reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1, 1, 32)     64          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 50, 50, 32)   0           batch_normalization_67[0][0]     \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 50, 50, 32)   0           multiply_5[0][0]                 \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 50, 50, 32)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 50, 50, 32)   9248        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 50, 50, 32)   128         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 50, 50, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 50, 50, 32)   9248        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 50, 50, 32)   128         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 32)           0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1, 32)     0           global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1, 1, 2)      64          reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1, 1, 32)     64          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 50, 50, 32)   0           batch_normalization_69[0][0]     \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 50, 50, 32)   0           multiply_6[0][0]                 \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 50, 50, 32)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 25, 25, 64)   18496       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 25, 25, 64)   256         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 25, 64)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 25, 25, 64)   36928       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 25, 25, 64)   256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 64)           0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1, 1, 4)      256         reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1, 1, 64)     256         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 25, 25, 64)   0           batch_normalization_71[0][0]     \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 25, 25, 64)   2112        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 25, 25, 64)   0           multiply_7[0][0]                 \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 25, 25, 64)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 25, 25, 64)   36928       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 25, 25, 64)   256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 25, 25, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 25, 25, 64)   36928       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 25, 25, 64)   256         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 64)           0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1, 1, 4)      256         reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1, 1, 64)     256         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 25, 25, 64)   0           batch_normalization_73[0][0]     \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 25, 25, 64)   0           multiply_8[0][0]                 \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 25, 25, 64)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 25, 25, 64)   36928       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 25, 25, 64)   256         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 25, 25, 64)   0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 25, 25, 64)   36928       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 25, 25, 64)   256         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 64)           0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1, 1, 4)      256         reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1, 1, 64)     256         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 25, 25, 64)   0           batch_normalization_75[0][0]     \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 25, 25, 64)   0           multiply_9[0][0]                 \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 25, 25, 64)   0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 13, 13, 128)  73856       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 13, 13, 128)  512         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 13, 13, 128)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 13, 13, 128)  147584      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 13, 13, 128)  512         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 128)          0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1, 128)    0           global_average_pooling2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1, 1, 8)      1024        reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1, 1, 128)    1024        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 13, 13, 128)  0           batch_normalization_77[0][0]     \n",
      "                                                                 dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 13, 13, 128)  8320        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 13, 13, 128)  0           multiply_10[0][0]                \n",
      "                                                                 conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 13, 13, 128)  0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 13, 13, 128)  147584      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 13, 13, 128)  512         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 13, 13, 128)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 13, 13, 128)  147584      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 13, 13, 128)  512         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 128)          0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1, 128)    0           global_average_pooling2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1, 1, 8)      1024        reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1, 1, 128)    1024        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 13, 13, 128)  0           batch_normalization_79[0][0]     \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 13, 13, 128)  0           multiply_11[0][0]                \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 13, 13, 128)  0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 13, 13, 128)  147584      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 13, 13, 128)  512         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 13, 13, 128)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 13, 13, 128)  147584      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 13, 13, 128)  512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_12 (Gl (None, 128)          0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1, 128)    0           global_average_pooling2d_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1, 1, 8)      1024        reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1, 1, 128)    1024        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 13, 13, 128)  0           batch_normalization_81[0][0]     \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 13, 13, 128)  0           multiply_12[0][0]                \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 13, 13, 128)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 6, 6, 128)    0           activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 4608)         0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            4609        flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,109,585\n",
      "Trainable params: 1,106,673\n",
      "Non-trainable params: 2,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#ResNetF with SE\n",
    "\n",
    "input_shape = (100, 100, 2)\n",
    "\n",
    "inputs = Input(shape=input_shape)  # output (1, 100, 100)\n",
    "y = resnet_layer(inputs=inputs, num_filters=16, strides=1)  # output (16, 100, 100)\n",
    "\n",
    "# stack 0\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "# stack 1\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=2)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "# linear projection\n",
    "y = resnet_layer(inputs=y, num_filters=32, kernel_size=1, strides=2, activation=None, batch_normalization=False)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "# stack 2\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=2)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "# linear projection\n",
    "y = resnet_layer(inputs=y, num_filters=64, kernel_size=1, strides=2, activation=None, batch_normalization=False)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "# stack 2\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=2)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "# linear projection\n",
    "y = resnet_layer(inputs=y, num_filters=128, kernel_size=1, strides=2, activation=None,\n",
    "                 batch_normalization=False)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "# squeeze and excite block\n",
    "x = squeeze_excite_block(x)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=2)(y)\n",
    "y = Flatten()(x)\n",
    "outputs = Dense(1, activation='sigmoid', kernel_initializer='he_normal')(y)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResnetH\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "input_shape = (2, self.img_rows, self.img_cols)\n",
    "\n",
    "inputs = Input(shape=input_shape)  # output (1, 100, 100)\n",
    "y = resnet_layer(inputs=inputs, num_filters=8, strides=1)  # output (16, 100, 100)\n",
    "\n",
    "# stack 0\n",
    "x = resnet_layer(inputs=y, num_filters=8, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=8, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=8, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=8, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=8, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=8, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "# stack 0\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=2)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "# linear projection\n",
    "y = resnet_layer(inputs=y, num_filters=16, kernel_size=1, strides=2, activation=None, batch_normalization=False)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=16, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=16, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "# stack 1\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=2)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "# linear projection\n",
    "y = resnet_layer(inputs=y, num_filters=32, kernel_size=1, strides=2, activation=None, batch_normalization=False)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=32, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=32, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "# stack 2\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=2)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "# linear projection\n",
    "y = resnet_layer(inputs=y, num_filters=64, kernel_size=1, strides=2, activation=None, batch_normalization=False)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=64, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=64, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "# stack 2\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=2)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "# linear projection\n",
    "y = resnet_layer(inputs=y, num_filters=128, kernel_size=1, strides=2, activation=None,\n",
    "                 batch_normalization=False)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = resnet_layer(inputs=y, num_filters=128, strides=1)\n",
    "x = resnet_layer(inputs=x, num_filters=128, strides=1, activation=None)\n",
    "x = keras.layers.add([x, y])\n",
    "y = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=2)(y)\n",
    "y = Flatten()(x)\n",
    "outputs = Dense(1, activation='linear', kernel_initializer='he_normal')(y)\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
